{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ef5c068-3af9-4e5f-858f-268a595a6413",
   "metadata": {},
   "source": [
    "# Description\n",
    "In this Notebook, we will try to parse each names into dependency trees, and try to identify who ismodifier and who is modified. Then we will conclude that the percentage of use of MPM structure. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0149cac-7e45-4a9e-b08b-c538406e914f",
   "metadata": {},
   "source": [
    "# Read data\n",
    "In order to save time, we will only load some part of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4829e542-5211-498f-b9ea-d5bc0fcc1456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>nameType</th>\n",
       "      <th>nameScope</th>\n",
       "      <th>projectSize</th>\n",
       "      <th>authorName</th>\n",
       "      <th>authorProficiency</th>\n",
       "      <th>authorLocation</th>\n",
       "      <th>terms</th>\n",
       "      <th>namingConvention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4120668</td>\n",
       "      <td>sphere_params</td>\n",
       "      <td>variable</td>\n",
       "      <td>FunctionScope</td>\n",
       "      <td>12269</td>\n",
       "      <td>yoursmengle</td>\n",
       "      <td>&gt;100</td>\n",
       "      <td>China</td>\n",
       "      <td>[sphere, params]</td>\n",
       "      <td>Snake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2966661</td>\n",
       "      <td>test_default_load_files</td>\n",
       "      <td>function</td>\n",
       "      <td>GlobalScope</td>\n",
       "      <td>63230</td>\n",
       "      <td>chenxingqiang</td>\n",
       "      <td>&gt;100</td>\n",
       "      <td>China</td>\n",
       "      <td>[test, default, load, files]</td>\n",
       "      <td>Snake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1947457</td>\n",
       "      <td>avg_kl_loss</td>\n",
       "      <td>variable</td>\n",
       "      <td>FunctionScope</td>\n",
       "      <td>346856</td>\n",
       "      <td>dyllanwli</td>\n",
       "      <td>50..100</td>\n",
       "      <td>China</td>\n",
       "      <td>[avg, kl, loss]</td>\n",
       "      <td>Snake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3040385</td>\n",
       "      <td>all_zero_samples</td>\n",
       "      <td>variable</td>\n",
       "      <td>FunctionScope</td>\n",
       "      <td>58646</td>\n",
       "      <td>chenxingqiang</td>\n",
       "      <td>&gt;100</td>\n",
       "      <td>China</td>\n",
       "      <td>[all, zero, samples]</td>\n",
       "      <td>Snake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1623071</td>\n",
       "      <td>max</td>\n",
       "      <td>variable</td>\n",
       "      <td>FunctionScope</td>\n",
       "      <td>71173</td>\n",
       "      <td>wr786</td>\n",
       "      <td>50..100</td>\n",
       "      <td>China</td>\n",
       "      <td>[max]</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>5853414</td>\n",
       "      <td>uwline</td>\n",
       "      <td>variable</td>\n",
       "      <td>FunctionScope</td>\n",
       "      <td>18573</td>\n",
       "      <td>brycepg</td>\n",
       "      <td>50..100</td>\n",
       "      <td>USA</td>\n",
       "      <td>[uwline]</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>7259206</td>\n",
       "      <td>compare</td>\n",
       "      <td>variable</td>\n",
       "      <td>FunctionScope</td>\n",
       "      <td>36024</td>\n",
       "      <td>yask123</td>\n",
       "      <td>&gt;100</td>\n",
       "      <td>USA</td>\n",
       "      <td>[compare]</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>4896029</td>\n",
       "      <td>hits</td>\n",
       "      <td>variable</td>\n",
       "      <td>FunctionScope</td>\n",
       "      <td>21484</td>\n",
       "      <td>scottgs</td>\n",
       "      <td>&lt;50</td>\n",
       "      <td>USA</td>\n",
       "      <td>[hits]</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>8030290</td>\n",
       "      <td>waiter</td>\n",
       "      <td>variable</td>\n",
       "      <td>FunctionScope</td>\n",
       "      <td>66767</td>\n",
       "      <td>itamaro</td>\n",
       "      <td>&gt;100</td>\n",
       "      <td>USA</td>\n",
       "      <td>[waiter]</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>6845319</td>\n",
       "      <td>item_caveStoneHelmetID</td>\n",
       "      <td>variable</td>\n",
       "      <td>GlobalScope</td>\n",
       "      <td>3885</td>\n",
       "      <td>seanpm2001</td>\n",
       "      <td>&gt;100</td>\n",
       "      <td>USA</td>\n",
       "      <td>[item, cave, ID, Stone, Helmet]</td>\n",
       "      <td>non-convention</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                     name  nameType      nameScope  \\\n",
       "0       4120668            sphere_params  variable  FunctionScope   \n",
       "1       2966661  test_default_load_files  function    GlobalScope   \n",
       "2       1947457              avg_kl_loss  variable  FunctionScope   \n",
       "3       3040385         all_zero_samples  variable  FunctionScope   \n",
       "4       1623071                      max  variable  FunctionScope   \n",
       "...         ...                      ...       ...            ...   \n",
       "199995  5853414                   uwline  variable  FunctionScope   \n",
       "199996  7259206                  compare  variable  FunctionScope   \n",
       "199997  4896029                     hits  variable  FunctionScope   \n",
       "199998  8030290                   waiter  variable  FunctionScope   \n",
       "199999  6845319   item_caveStoneHelmetID  variable    GlobalScope   \n",
       "\n",
       "        projectSize     authorName authorProficiency authorLocation  \\\n",
       "0             12269    yoursmengle              >100          China   \n",
       "1             63230  chenxingqiang              >100          China   \n",
       "2            346856      dyllanwli           50..100          China   \n",
       "3             58646  chenxingqiang              >100          China   \n",
       "4             71173          wr786           50..100          China   \n",
       "...             ...            ...               ...            ...   \n",
       "199995        18573        brycepg           50..100            USA   \n",
       "199996        36024        yask123              >100            USA   \n",
       "199997        21484        scottgs               <50            USA   \n",
       "199998        66767        itamaro              >100            USA   \n",
       "199999         3885     seanpm2001              >100            USA   \n",
       "\n",
       "                                  terms namingConvention  \n",
       "0                      [sphere, params]            Snake  \n",
       "1          [test, default, load, files]            Snake  \n",
       "2                       [avg, kl, loss]            Snake  \n",
       "3                  [all, zero, samples]            Snake  \n",
       "4                                 [max]          Unknown  \n",
       "...                                 ...              ...  \n",
       "199995                         [uwline]          Unknown  \n",
       "199996                        [compare]          Unknown  \n",
       "199997                           [hits]          Unknown  \n",
       "199998                         [waiter]          Unknown  \n",
       "199999  [item, cave, ID, Stone, Helmet]   non-convention  \n",
       "\n",
       "[200000 rows x 10 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "name_table = \"NameTable\"\n",
    "conn = sqlite3.connect('../ZipfLawAnalysis/data.db')\n",
    "query = f\"\"\"SELECT *\n",
    "FROM (\n",
    "    SELECT *\n",
    "    FROM {name_table}\n",
    "    WHERE authorLocation = 'China'\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 100000\n",
    ") AS Chinese_sample\n",
    "UNION ALL\n",
    "SELECT *\n",
    "FROM (\n",
    "    SELECT *\n",
    "    FROM {name_table}\n",
    "    WHERE authorLocation = 'USA'\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 100000\n",
    ") AS USA_sample;\"\"\"\n",
    "# takes 10 second to run 100k\n",
    "df = pd.read_sql_query(query, conn)\n",
    "import json\n",
    "df['terms'] = df.terms.apply(json.loads)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a495834-7a68-405a-9ad4-20f494ad9f82",
   "metadata": {},
   "source": [
    "For now convert abbreviation on the fly. There is a lot of problem regarding abbreviations, and I am just putting it off for now. Assume that the abbreviation map will map names to the correct names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31ceb20a-0f4e-4cde-a15f-9328b8530e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "abbrev_table = \"AbbreviationMap\"\n",
    "query = f\"SELECT * FROM {abbrev_table}\"\n",
    "df_abbrev_map = pd.read_sql_query(query, conn)\n",
    "\n",
    "# I will use a better dictionary: ENABLE (Enhanced North American Benchmark Lexicon)\n",
    "with open('../ZipfLawAnalysis/SavedFiles/atebits.txt', 'r') as file:\n",
    "    words = file.read().splitlines()\n",
    "english_dictionary =  set(words)\n",
    "\n",
    "# the dictionary that maps abbreviation back to original words\n",
    "abbrev_map = dict(zip(df_abbrev_map['term'], df_abbrev_map['abbrev_meaning']))\n",
    "# because the confidence of preicting single letter is too low, I would give up all the single letters\n",
    "# also there are ones that ChatGPT cannot recognize, generally too wierd ones, so I will get rid of those too. (277 of them)\n",
    "# also there are about 20k duplicates due to capitalization, here we will combine them together first. ???\n",
    "filtered_abbrev_map = {k: v for k, v in abbrev_map.items() if v != '-1'}\n",
    "\n",
    "# function that checks if it's a real word\n",
    "def lookup_terms(term):\n",
    "    return term.lower() in english_dictionary\n",
    "\n",
    "def map_terms_to_actual_terms(terms):\n",
    "    # if it's dictionary word, it will not be in the dictionary, or it might be something that GPT cannot guess. \n",
    "    # either way, the original terms will be in the list. Else, the translated terms will be in the list.\n",
    "    return [filtered_abbrev_map.get(term, term) for term in terms]\n",
    "\n",
    "df['actual_terms'] = df['terms'].apply(map_terms_to_actual_terms)   \n",
    "\n",
    "temp = df['terms'].apply('_'.join).str.lower()\n",
    "df['standarized_name'] = temp\n",
    "\n",
    "temp = df['actual_terms'].apply('_'.join).str.lower().str.replace(\" \", \"_\")\n",
    "df['atual_standarized_name'] = temp\n",
    "\n",
    "# we use atual_standarized_name to define actual_terms so that we can get rid of the space\n",
    "# sometimes pd will return view of df not the actual df, depends on the RAM\n",
    "df = df.copy()\n",
    "df['actual_terms'] = df['atual_standarized_name'].apply(lambda x: x.split('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b02def4-a2aa-442f-bb41-f34f84d66d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>nameType</th>\n",
       "      <th>nameScope</th>\n",
       "      <th>projectSize</th>\n",
       "      <th>authorName</th>\n",
       "      <th>authorProficiency</th>\n",
       "      <th>authorLocation</th>\n",
       "      <th>terms</th>\n",
       "      <th>namingConvention</th>\n",
       "      <th>actual_terms</th>\n",
       "      <th>standarized_name</th>\n",
       "      <th>atual_standarized_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4120668</td>\n",
       "      <td>sphere_params</td>\n",
       "      <td>variable</td>\n",
       "      <td>FunctionScope</td>\n",
       "      <td>12269</td>\n",
       "      <td>yoursmengle</td>\n",
       "      <td>&gt;100</td>\n",
       "      <td>China</td>\n",
       "      <td>[sphere, params]</td>\n",
       "      <td>Snake</td>\n",
       "      <td>[sphere, parameters]</td>\n",
       "      <td>sphere_params</td>\n",
       "      <td>sphere_parameters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2966661</td>\n",
       "      <td>test_default_load_files</td>\n",
       "      <td>function</td>\n",
       "      <td>GlobalScope</td>\n",
       "      <td>63230</td>\n",
       "      <td>chenxingqiang</td>\n",
       "      <td>&gt;100</td>\n",
       "      <td>China</td>\n",
       "      <td>[test, default, load, files]</td>\n",
       "      <td>Snake</td>\n",
       "      <td>[test, default, load, files]</td>\n",
       "      <td>test_default_load_files</td>\n",
       "      <td>test_default_load_files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1947457</td>\n",
       "      <td>avg_kl_loss</td>\n",
       "      <td>variable</td>\n",
       "      <td>FunctionScope</td>\n",
       "      <td>346856</td>\n",
       "      <td>dyllanwli</td>\n",
       "      <td>50..100</td>\n",
       "      <td>China</td>\n",
       "      <td>[avg, kl, loss]</td>\n",
       "      <td>Snake</td>\n",
       "      <td>[average, kullback-leibler, loss]</td>\n",
       "      <td>avg_kl_loss</td>\n",
       "      <td>average_kullback-leibler_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3040385</td>\n",
       "      <td>all_zero_samples</td>\n",
       "      <td>variable</td>\n",
       "      <td>FunctionScope</td>\n",
       "      <td>58646</td>\n",
       "      <td>chenxingqiang</td>\n",
       "      <td>&gt;100</td>\n",
       "      <td>China</td>\n",
       "      <td>[all, zero, samples]</td>\n",
       "      <td>Snake</td>\n",
       "      <td>[all, zero, samples]</td>\n",
       "      <td>all_zero_samples</td>\n",
       "      <td>all_zero_samples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1623071</td>\n",
       "      <td>max</td>\n",
       "      <td>variable</td>\n",
       "      <td>FunctionScope</td>\n",
       "      <td>71173</td>\n",
       "      <td>wr786</td>\n",
       "      <td>50..100</td>\n",
       "      <td>China</td>\n",
       "      <td>[max]</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>[max]</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>5853414</td>\n",
       "      <td>uwline</td>\n",
       "      <td>variable</td>\n",
       "      <td>FunctionScope</td>\n",
       "      <td>18573</td>\n",
       "      <td>brycepg</td>\n",
       "      <td>50..100</td>\n",
       "      <td>USA</td>\n",
       "      <td>[uwline]</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>[universal, windows, line]</td>\n",
       "      <td>uwline</td>\n",
       "      <td>universal_windows_line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>7259206</td>\n",
       "      <td>compare</td>\n",
       "      <td>variable</td>\n",
       "      <td>FunctionScope</td>\n",
       "      <td>36024</td>\n",
       "      <td>yask123</td>\n",
       "      <td>&gt;100</td>\n",
       "      <td>USA</td>\n",
       "      <td>[compare]</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>[compare]</td>\n",
       "      <td>compare</td>\n",
       "      <td>compare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>4896029</td>\n",
       "      <td>hits</td>\n",
       "      <td>variable</td>\n",
       "      <td>FunctionScope</td>\n",
       "      <td>21484</td>\n",
       "      <td>scottgs</td>\n",
       "      <td>&lt;50</td>\n",
       "      <td>USA</td>\n",
       "      <td>[hits]</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>[hits]</td>\n",
       "      <td>hits</td>\n",
       "      <td>hits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>8030290</td>\n",
       "      <td>waiter</td>\n",
       "      <td>variable</td>\n",
       "      <td>FunctionScope</td>\n",
       "      <td>66767</td>\n",
       "      <td>itamaro</td>\n",
       "      <td>&gt;100</td>\n",
       "      <td>USA</td>\n",
       "      <td>[waiter]</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>[waiter]</td>\n",
       "      <td>waiter</td>\n",
       "      <td>waiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>6845319</td>\n",
       "      <td>item_caveStoneHelmetID</td>\n",
       "      <td>variable</td>\n",
       "      <td>GlobalScope</td>\n",
       "      <td>3885</td>\n",
       "      <td>seanpm2001</td>\n",
       "      <td>&gt;100</td>\n",
       "      <td>USA</td>\n",
       "      <td>[item, cave, ID, Stone, Helmet]</td>\n",
       "      <td>non-convention</td>\n",
       "      <td>[item, cave, id, stone, helmet]</td>\n",
       "      <td>item_cave_id_stone_helmet</td>\n",
       "      <td>item_cave_id_stone_helmet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                     name  nameType      nameScope  \\\n",
       "0       4120668            sphere_params  variable  FunctionScope   \n",
       "1       2966661  test_default_load_files  function    GlobalScope   \n",
       "2       1947457              avg_kl_loss  variable  FunctionScope   \n",
       "3       3040385         all_zero_samples  variable  FunctionScope   \n",
       "4       1623071                      max  variable  FunctionScope   \n",
       "...         ...                      ...       ...            ...   \n",
       "199995  5853414                   uwline  variable  FunctionScope   \n",
       "199996  7259206                  compare  variable  FunctionScope   \n",
       "199997  4896029                     hits  variable  FunctionScope   \n",
       "199998  8030290                   waiter  variable  FunctionScope   \n",
       "199999  6845319   item_caveStoneHelmetID  variable    GlobalScope   \n",
       "\n",
       "        projectSize     authorName authorProficiency authorLocation  \\\n",
       "0             12269    yoursmengle              >100          China   \n",
       "1             63230  chenxingqiang              >100          China   \n",
       "2            346856      dyllanwli           50..100          China   \n",
       "3             58646  chenxingqiang              >100          China   \n",
       "4             71173          wr786           50..100          China   \n",
       "...             ...            ...               ...            ...   \n",
       "199995        18573        brycepg           50..100            USA   \n",
       "199996        36024        yask123              >100            USA   \n",
       "199997        21484        scottgs               <50            USA   \n",
       "199998        66767        itamaro              >100            USA   \n",
       "199999         3885     seanpm2001              >100            USA   \n",
       "\n",
       "                                  terms namingConvention  \\\n",
       "0                      [sphere, params]            Snake   \n",
       "1          [test, default, load, files]            Snake   \n",
       "2                       [avg, kl, loss]            Snake   \n",
       "3                  [all, zero, samples]            Snake   \n",
       "4                                 [max]          Unknown   \n",
       "...                                 ...              ...   \n",
       "199995                         [uwline]          Unknown   \n",
       "199996                        [compare]          Unknown   \n",
       "199997                           [hits]          Unknown   \n",
       "199998                         [waiter]          Unknown   \n",
       "199999  [item, cave, ID, Stone, Helmet]   non-convention   \n",
       "\n",
       "                             actual_terms           standarized_name  \\\n",
       "0                    [sphere, parameters]              sphere_params   \n",
       "1            [test, default, load, files]    test_default_load_files   \n",
       "2       [average, kullback-leibler, loss]                avg_kl_loss   \n",
       "3                    [all, zero, samples]           all_zero_samples   \n",
       "4                                   [max]                        max   \n",
       "...                                   ...                        ...   \n",
       "199995         [universal, windows, line]                     uwline   \n",
       "199996                          [compare]                    compare   \n",
       "199997                             [hits]                       hits   \n",
       "199998                           [waiter]                     waiter   \n",
       "199999    [item, cave, id, stone, helmet]  item_cave_id_stone_helmet   \n",
       "\n",
       "               atual_standarized_name  \n",
       "0                   sphere_parameters  \n",
       "1             test_default_load_files  \n",
       "2       average_kullback-leibler_loss  \n",
       "3                    all_zero_samples  \n",
       "4                                 max  \n",
       "...                               ...  \n",
       "199995         universal_windows_line  \n",
       "199996                        compare  \n",
       "199997                           hits  \n",
       "199998                         waiter  \n",
       "199999      item_cave_id_stone_helmet  \n",
       "\n",
       "[200000 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb38ec2-7a01-42a1-a057-97dfdacae712",
   "metadata": {},
   "source": [
    "# Dependency Parsing\n",
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c3c22b-75fa-4027-bb5e-fb398ac1594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !python -m spacy download en\n",
    "import spacy\n",
    "\n",
    "# Load the English NLP model\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4323b092-f78f-4682-8178-d16297c4d647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the                0 det        dog                 1\n",
      "dog                1 nsubj      eating              3\n",
      "is                 2 aux        eating              3\n",
      "eating             3 ROOT       eating              3\n",
      "hot                4 amod       dog                 5\n",
      "dog                5 dobj       eating              3\n",
      ".                  6 punct      eating              3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example: Process a sentence\n",
    "doc = nlp(\"the dog is eating hot dog.\")\n",
    "\n",
    "# Print the dependency parsing results\n",
    "for token in doc:\n",
    "    print(f'{token.text:{10}}{token.i:{10}} {token.dep_:{10}} {token.head.text:{10}} {token.head.i:{10}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccdafff9-15f4-4bac-9c71-f335fdefeccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"a402d7d7b6b643f8a4b7cd8aa0256252-0\" class=\"displacy\" width=\"1100\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">dog</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">eating</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">hot</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">dog.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a402d7d7b6b643f8a4b7cd8aa0256252-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a402d7d7b6b643f8a4b7cd8aa0256252-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a402d7d7b6b643f8a4b7cd8aa0256252-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a402d7d7b6b643f8a4b7cd8aa0256252-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a402d7d7b6b643f8a4b7cd8aa0256252-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a402d7d7b6b643f8a4b7cd8aa0256252-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a402d7d7b6b643f8a4b7cd8aa0256252-0-3\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a402d7d7b6b643f8a4b7cd8aa0256252-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,179.0 L762,167.0 778,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a402d7d7b6b643f8a4b7cd8aa0256252-0-4\" stroke-width=\"2px\" d=\"M595,177.0 C595,2.0 925.0,2.0 925.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a402d7d7b6b643f8a4b7cd8aa0256252-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,179.0 L933.0,167.0 917.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"dep\", page=\"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26d561b-12d4-4d93-b3e6-7786a809490d",
   "metadata": {},
   "source": [
    "## perform on names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24eb8fc9-33be-49eb-bc5f-c117efd66c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>nameType</th>\n",
       "      <th>nameScope</th>\n",
       "      <th>projectSize</th>\n",
       "      <th>authorName</th>\n",
       "      <th>authorProficiency</th>\n",
       "      <th>authorLocation</th>\n",
       "      <th>terms</th>\n",
       "      <th>namingConvention</th>\n",
       "      <th>actual_terms</th>\n",
       "      <th>standarized_name</th>\n",
       "      <th>atual_standarized_name</th>\n",
       "      <th>phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2966661</td>\n",
       "      <td>test_default_load_files</td>\n",
       "      <td>function</td>\n",
       "      <td>GlobalScope</td>\n",
       "      <td>63230</td>\n",
       "      <td>chenxingqiang</td>\n",
       "      <td>&gt;100</td>\n",
       "      <td>China</td>\n",
       "      <td>[test, default, load, files]</td>\n",
       "      <td>Snake</td>\n",
       "      <td>[test, default, load, files]</td>\n",
       "      <td>test_default_load_files</td>\n",
       "      <td>test_default_load_files</td>\n",
       "      <td>test default load files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1947457</td>\n",
       "      <td>avg_kl_loss</td>\n",
       "      <td>variable</td>\n",
       "      <td>FunctionScope</td>\n",
       "      <td>346856</td>\n",
       "      <td>dyllanwli</td>\n",
       "      <td>50..100</td>\n",
       "      <td>China</td>\n",
       "      <td>[avg, kl, loss]</td>\n",
       "      <td>Snake</td>\n",
       "      <td>[average, kullback-leibler, loss]</td>\n",
       "      <td>avg_kl_loss</td>\n",
       "      <td>average_kullback-leibler_loss</td>\n",
       "      <td>average kullback-leibler loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3040385</td>\n",
       "      <td>all_zero_samples</td>\n",
       "      <td>variable</td>\n",
       "      <td>FunctionScope</td>\n",
       "      <td>58646</td>\n",
       "      <td>chenxingqiang</td>\n",
       "      <td>&gt;100</td>\n",
       "      <td>China</td>\n",
       "      <td>[all, zero, samples]</td>\n",
       "      <td>Snake</td>\n",
       "      <td>[all, zero, samples]</td>\n",
       "      <td>all_zero_samples</td>\n",
       "      <td>all_zero_samples</td>\n",
       "      <td>all zero samples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2117835</td>\n",
       "      <td>parse_content_disposition</td>\n",
       "      <td>function</td>\n",
       "      <td>GlobalScope</td>\n",
       "      <td>11480</td>\n",
       "      <td>asapsonter</td>\n",
       "      <td>50..100</td>\n",
       "      <td>China</td>\n",
       "      <td>[parse, content, disposition]</td>\n",
       "      <td>Snake</td>\n",
       "      <td>[parse, content, disposition]</td>\n",
       "      <td>parse_content_disposition</td>\n",
       "      <td>parse_content_disposition</td>\n",
       "      <td>parse content disposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2035907</td>\n",
       "      <td>_is_platform_dependent</td>\n",
       "      <td>function</td>\n",
       "      <td>FunctionScope</td>\n",
       "      <td>35987</td>\n",
       "      <td>asapsonter</td>\n",
       "      <td>50..100</td>\n",
       "      <td>China</td>\n",
       "      <td>[is, platform, dependent]</td>\n",
       "      <td>Snake</td>\n",
       "      <td>[is, platform, dependent]</td>\n",
       "      <td>is_platform_dependent</td>\n",
       "      <td>is_platform_dependent</td>\n",
       "      <td>is platform dependent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199983</th>\n",
       "      <td>5944068</td>\n",
       "      <td>idna_info</td>\n",
       "      <td>variable</td>\n",
       "      <td>FunctionScope</td>\n",
       "      <td>7142</td>\n",
       "      <td>hang10z</td>\n",
       "      <td>50..100</td>\n",
       "      <td>USA</td>\n",
       "      <td>[idna, info]</td>\n",
       "      <td>Snake</td>\n",
       "      <td>[internationalized, domain, names, in, applica...</td>\n",
       "      <td>idna_info</td>\n",
       "      <td>internationalized_domain_names_in_applications...</td>\n",
       "      <td>internationalized domain names in applications...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199985</th>\n",
       "      <td>6260123</td>\n",
       "      <td>test_wide_repr_wide_columns</td>\n",
       "      <td>function</td>\n",
       "      <td>FunctionScope</td>\n",
       "      <td>53314</td>\n",
       "      <td>GautamGottipati</td>\n",
       "      <td>50..100</td>\n",
       "      <td>USA</td>\n",
       "      <td>[test, wide, repr, wide, columns]</td>\n",
       "      <td>Snake</td>\n",
       "      <td>[test, wide, representation, wide, columns]</td>\n",
       "      <td>test_wide_repr_wide_columns</td>\n",
       "      <td>test_wide_representation_wide_columns</td>\n",
       "      <td>test wide representation wide columns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199992</th>\n",
       "      <td>7595055</td>\n",
       "      <td>fcompiler_class</td>\n",
       "      <td>variable</td>\n",
       "      <td>GlobalScope</td>\n",
       "      <td>20010</td>\n",
       "      <td>kdschlosser</td>\n",
       "      <td>&gt;100</td>\n",
       "      <td>USA</td>\n",
       "      <td>[fcompiler, class]</td>\n",
       "      <td>Snake</td>\n",
       "      <td>[fortran, compiler, class]</td>\n",
       "      <td>fcompiler_class</td>\n",
       "      <td>fortran_compiler_class</td>\n",
       "      <td>fortran compiler class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>5853414</td>\n",
       "      <td>uwline</td>\n",
       "      <td>variable</td>\n",
       "      <td>FunctionScope</td>\n",
       "      <td>18573</td>\n",
       "      <td>brycepg</td>\n",
       "      <td>50..100</td>\n",
       "      <td>USA</td>\n",
       "      <td>[uwline]</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>[universal, windows, line]</td>\n",
       "      <td>uwline</td>\n",
       "      <td>universal_windows_line</td>\n",
       "      <td>universal windows line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>6845319</td>\n",
       "      <td>item_caveStoneHelmetID</td>\n",
       "      <td>variable</td>\n",
       "      <td>GlobalScope</td>\n",
       "      <td>3885</td>\n",
       "      <td>seanpm2001</td>\n",
       "      <td>&gt;100</td>\n",
       "      <td>USA</td>\n",
       "      <td>[item, cave, ID, Stone, Helmet]</td>\n",
       "      <td>non-convention</td>\n",
       "      <td>[item, cave, id, stone, helmet]</td>\n",
       "      <td>item_cave_id_stone_helmet</td>\n",
       "      <td>item_cave_id_stone_helmet</td>\n",
       "      <td>item cave id stone helmet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50820 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                         name  nameType      nameScope  \\\n",
       "1       2966661      test_default_load_files  function    GlobalScope   \n",
       "2       1947457                  avg_kl_loss  variable  FunctionScope   \n",
       "3       3040385             all_zero_samples  variable  FunctionScope   \n",
       "7       2117835    parse_content_disposition  function    GlobalScope   \n",
       "8       2035907       _is_platform_dependent  function  FunctionScope   \n",
       "...         ...                          ...       ...            ...   \n",
       "199983  5944068                    idna_info  variable  FunctionScope   \n",
       "199985  6260123  test_wide_repr_wide_columns  function  FunctionScope   \n",
       "199992  7595055              fcompiler_class  variable    GlobalScope   \n",
       "199995  5853414                       uwline  variable  FunctionScope   \n",
       "199999  6845319       item_caveStoneHelmetID  variable    GlobalScope   \n",
       "\n",
       "        projectSize       authorName authorProficiency authorLocation  \\\n",
       "1             63230    chenxingqiang              >100          China   \n",
       "2            346856        dyllanwli           50..100          China   \n",
       "3             58646    chenxingqiang              >100          China   \n",
       "7             11480       asapsonter           50..100          China   \n",
       "8             35987       asapsonter           50..100          China   \n",
       "...             ...              ...               ...            ...   \n",
       "199983         7142          hang10z           50..100            USA   \n",
       "199985        53314  GautamGottipati           50..100            USA   \n",
       "199992        20010      kdschlosser              >100            USA   \n",
       "199995        18573          brycepg           50..100            USA   \n",
       "199999         3885       seanpm2001              >100            USA   \n",
       "\n",
       "                                    terms namingConvention  \\\n",
       "1            [test, default, load, files]            Snake   \n",
       "2                         [avg, kl, loss]            Snake   \n",
       "3                    [all, zero, samples]            Snake   \n",
       "7           [parse, content, disposition]            Snake   \n",
       "8               [is, platform, dependent]            Snake   \n",
       "...                                   ...              ...   \n",
       "199983                       [idna, info]            Snake   \n",
       "199985  [test, wide, repr, wide, columns]            Snake   \n",
       "199992                 [fcompiler, class]            Snake   \n",
       "199995                           [uwline]          Unknown   \n",
       "199999    [item, cave, ID, Stone, Helmet]   non-convention   \n",
       "\n",
       "                                             actual_terms  \\\n",
       "1                            [test, default, load, files]   \n",
       "2                       [average, kullback-leibler, loss]   \n",
       "3                                    [all, zero, samples]   \n",
       "7                           [parse, content, disposition]   \n",
       "8                               [is, platform, dependent]   \n",
       "...                                                   ...   \n",
       "199983  [internationalized, domain, names, in, applica...   \n",
       "199985        [test, wide, representation, wide, columns]   \n",
       "199992                         [fortran, compiler, class]   \n",
       "199995                         [universal, windows, line]   \n",
       "199999                    [item, cave, id, stone, helmet]   \n",
       "\n",
       "                   standarized_name  \\\n",
       "1           test_default_load_files   \n",
       "2                       avg_kl_loss   \n",
       "3                  all_zero_samples   \n",
       "7         parse_content_disposition   \n",
       "8             is_platform_dependent   \n",
       "...                             ...   \n",
       "199983                    idna_info   \n",
       "199985  test_wide_repr_wide_columns   \n",
       "199992              fcompiler_class   \n",
       "199995                       uwline   \n",
       "199999    item_cave_id_stone_helmet   \n",
       "\n",
       "                                   atual_standarized_name  \\\n",
       "1                                 test_default_load_files   \n",
       "2                           average_kullback-leibler_loss   \n",
       "3                                        all_zero_samples   \n",
       "7                               parse_content_disposition   \n",
       "8                                   is_platform_dependent   \n",
       "...                                                   ...   \n",
       "199983  internationalized_domain_names_in_applications...   \n",
       "199985              test_wide_representation_wide_columns   \n",
       "199992                             fortran_compiler_class   \n",
       "199995                             universal_windows_line   \n",
       "199999                          item_cave_id_stone_helmet   \n",
       "\n",
       "                                                   phrase  \n",
       "1                                 test default load files  \n",
       "2                           average kullback-leibler loss  \n",
       "3                                        all zero samples  \n",
       "7                               parse content disposition  \n",
       "8                                   is platform dependent  \n",
       "...                                                   ...  \n",
       "199983  internationalized domain names in applications...  \n",
       "199985              test wide representation wide columns  \n",
       "199992                             fortran compiler class  \n",
       "199995                             universal windows line  \n",
       "199999                          item cave id stone helmet  \n",
       "\n",
       "[50820 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_phrase = df[df[\"actual_terms\"].str.len() > 2].copy()\n",
    "df_phrase[\"phrase\"] = df_phrase[\"actual_terms\"].apply(\" \".join)\n",
    "df_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b59e971b-052a-401b-9638-4a5deb3786b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "modifiers = {'AMOD', 'ADVCL', 'ACL', 'ADVMOD', 'APPOS', 'COMPOUND', 'META', 'NEG', 'NPMOD', 'POSS', 'PREP', 'RELCL', 'POBJ'}\n",
    "def count_MPM(phrase):\n",
    "    '''\n",
    "    This function will count number of MPM in the phrase, and number of non MPM. Used for df.apply()\n",
    "    Why do we count it? \n",
    "    1. Some phrases doesn't have a MPM structure: evaluate_data\n",
    "    2. Some phrases have some MPM and some not: starting_time_of_frame\n",
    "    '''\n",
    "    num_mpm, num_not_mpm = 0, 0\n",
    "    doc = nlp(phrase)\n",
    "    for token in doc:\n",
    "        if token.dep_.upper() in modifiers:\n",
    "            if token.i < token.head.i:\n",
    "                num_mpm += 1\n",
    "            else:\n",
    "                num_not_mpm += 1\n",
    "    return num_mpm, num_not_mpm\n",
    "\n",
    "temp = df_phrase[\"phrase\"].apply(count_MPM)\n",
    "df_phrase.reset_index(drop=True, inplace=True)\n",
    "df_phrase[[\"num_MPM\", \"num_not_MPM\"]] = pd.DataFrame(temp.to_list(), columns=[\"num_MPM\", \"num_not_MPM\"]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71b9f5c9-d21d-4318-b4dc-fde607cc8e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China\n",
      "MPM: 46616          non_mpm: 9111            total_sample:55727           percentage:0.8365065408150447 \n",
      "USA\n",
      "MPM: 54182          non_mpm: 10010           total_sample:64192           percentage:0.8440615653040877 \n"
     ]
    }
   ],
   "source": [
    "# get the chinese subset and USA subset\n",
    "df_china_phrase = df_phrase[df_phrase['authorLocation'] == 'China']\n",
    "df_usa_phrase = df_phrase[df_phrase['authorLocation'] == 'USA']\n",
    "\n",
    "for x, df_x_phrase in [('China', df_china_phrase), ('USA',df_usa_phrase)]:\n",
    "    num_mpm = df_x_phrase['num_MPM'].sum()\n",
    "    num_non_mpm = df_x_phrase['num_not_MPM'].sum()\n",
    "    total_sample = num_mpm + num_non_mpm\n",
    "    percentage = num_mpm/total_sample\n",
    "    print(x)\n",
    "    print(f\"MPM: {num_mpm: <15}non_mpm: {num_non_mpm: <15} total_sample:{total_sample:<15} percentage:{percentage: <15} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dbc919-98f4-43a6-b853-df988b492025",
   "metadata": {},
   "source": [
    "The result seems not great, How about the raw terms?  (replicate/override above results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af2dce86-6201-4677-a351-57ac73fbbccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China\n",
      "MPM: 27597          non_mpm: 5727            total_sample:33324           percentage:0.8281418797263234 \n",
      "USA\n",
      "MPM: 34239          non_mpm: 5322            total_sample:39561           percentage:0.8654735724577235 \n"
     ]
    }
   ],
   "source": [
    "df_phrase = df[df[\"terms\"].str.len() > 2].copy()\n",
    "df_phrase[\"phrase\"] = df_phrase[\"terms\"].apply(\" \".join)\n",
    "modifiers = {'AMOD', 'ADVCL', 'ACL', 'ADVMOD', 'APPOS', 'COMPOUND', 'META', 'NEG', 'NPMOD', 'POSS', 'PREP', 'RELCL', 'POBJ'}\n",
    "def count_MPM(phrase):\n",
    "    '''\n",
    "    This function will count number of MPM in the phrase, and number of non MPM. Used for df.apply()\n",
    "    Why do we count it? \n",
    "    1. Some phrases doesn't have a MPM structure: evaluate_data\n",
    "    2. Some phrases have some MPM and some not: starting_time_of_frame\n",
    "    '''\n",
    "    num_mpm, num_not_mpm = 0, 0\n",
    "    doc = nlp(phrase)\n",
    "    for token in doc:\n",
    "        if token.dep_.upper() in modifiers:\n",
    "            if token.i < token.head.i:\n",
    "                num_mpm += 1\n",
    "            else:\n",
    "                num_not_mpm += 1\n",
    "    return num_mpm, num_not_mpm\n",
    "\n",
    "temp = df_phrase[\"phrase\"].apply(count_MPM)\n",
    "df_phrase.reset_index(drop=True, inplace=True)\n",
    "df_phrase[[\"num_MPM\", \"num_not_MPM\"]] = pd.DataFrame(temp.to_list(), columns=[\"num_MPM\", \"num_not_MPM\"]).copy()\n",
    "# get the chinese subset and USA subset\n",
    "df_china_phrase = df_phrase[df_phrase['authorLocation'] == 'China']\n",
    "df_usa_phrase = df_phrase[df_phrase['authorLocation'] == 'USA']\n",
    "\n",
    "for x, df_x_phrase in [('China', df_china_phrase), ('USA',df_usa_phrase)]:\n",
    "    num_mpm = df_x_phrase['num_MPM'].sum()\n",
    "    num_non_mpm = df_x_phrase['num_not_MPM'].sum()\n",
    "    total_sample = num_mpm + num_non_mpm\n",
    "    percentage = num_mpm/total_sample\n",
    "    print(x)\n",
    "    print(f\"MPM: {num_mpm: <15}non_mpm: {num_non_mpm: <15} total_sample:{total_sample:<15} percentage:{percentage: <15} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c7cd64-1fb6-4036-bf79-82341d4c706b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
